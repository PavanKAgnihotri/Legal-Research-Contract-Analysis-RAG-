{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"langchain[google-genai]\" langchain-community faiss-cpu jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nykt1zLOGlpl",
        "outputId": "dd47e747-7b52-49b9-de6f-bd8818eb063b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: langchain[google-genai] in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (6.0.2)\n",
            "Collecting langchain-google-genai (from langchain[google-genai])\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines) (25.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[google-genai]) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[google-genai]) (4.14.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[google-genai]) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[google-genai]) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[google-genai]) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[google-genai]) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[google-genai]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[google-genai]) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain[google-genai]) (3.2.4)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai->langchain[google-genai])\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai->langchain[google-genai])\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.29.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain[google-genai]) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (4.9.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.6.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, mypy-extensions, marshmallow, jsonlines, faiss-cpu, typing-inspect, dataclasses-json, google-ai-generativelanguage, langchain-google-genai, langchain-community\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.12.0 filetype-1.2.0 google-ai-generativelanguage-0.6.18 jsonlines-4.0.0 langchain-community-0.3.27 langchain-google-genai-2.1.9 marshmallow-3.26.1 mypy-extensions-1.1.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "35b333d5d072415a957b4356b06db45a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw-IdMgfDYt6",
        "outputId": "488d42f9-30b9-4f13-ff39-784a3f940c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "{'id': 'cl:11126067', 'source': 'courtlistener', 'doc_type': 'case', 'text': \"          IN THE COURT OF CRIMINAL APPEALS\\n                      OF TEXAS\\n\\n                            NO. PD-0522-21, 0523-24,\\n                                0524-21, 0525-21\\n\\n\\n           EX PARTE ROBBIE GAIL CHARETTE, Appellant\\n\\n\\n On State’s Motion for Rehearing After Opinion on Appellant’s Petition\\n    for Discretionary Review from the Fourteenth Court of Appeals\\n                         Washington County\\n\\n            SCHENCK, P.J., delivered the opinion in which YEARY, KEEL,\\n      FINLEY, and PARKER, JJ., joined. RICHARDSON, J., filed a concurring\\n      opinion in which NEWELL, J., joined. NEWELL and MCCLURE, JJ.,\\n      concurred. WALKER, J., dissented.\\n\\n                                   OPINION\\n\\n      This matter is before us on rehearing. In our original opinion, the Court agreed\\n\\nthat Appellant’s pretrial writ of habeas corpus was properly before us as her\\n\\nchallenge presented jurisdictional and constitutional separation of powers concerns\\n\\ncentered on the question of whether the prosecution could proceed. We reaffirm that\\n\\x0c                                                                        CHARETTE — 2\\n\\n\\n\\ndecision. On the merits, we answered that any criminal prosecution brought without\\n\\neither an authorizing referral from Texas Ethics Commission (hereinafter, the\\n\\n“Commission” or the “TEC”) or following complete exhaustion of its civil process\\n\\nwould be barred as an interference with that body’s exclusive jurisdiction. On\\n\\nreconsideration, we find no such categorical bar expressed in the Constitution or the\\n\\nstatutes implemented pursuant to it. Neither do we find any basis in the record of\\n\\nthis case to suggest this prosecution would impermissibly impinge upon the\\n\\noperations of the TEC.\\n\\n      Accordingly, we withdraw our prior opinion reversing the court of appeals\\n\\nand affirm its judgment.\\n\\n                                   BACKGROUND\\n\\n      Appellant ran for the office of Judge of the Washington County Court at Law\\n\\nas a Republican candidate in 2018. After receiving allegations of misconduct during\\n\\nher primary campaign, a Washington County grand jury indicted Appellant for\\n\\n(1) knowing misrepresentation of the true source of campaign communications,\\n\\n(2) falsely representing in campaign communications, with knowledge of the falsity,\\n\\nthat she held a public office she in fact did not, (3) failing to timely file her personal\\n\\nfinancial statement, and (4) failing to maintain proper records of political\\n\\nexpenditures. Appellant filed a pretrial writ of habeas corpus in the district court,\\n\\nurging the indictment be quashed as void because the exclusive authority to\\n\\x0c                                                                                  CHARETTE — 3\\n\\n\\n\\ninvestigate and initiate prosecution was, by her argument, vested in the Texas Ethics\\n\\nCommission.1\\n\\n       The trial court disagreed and denied habeas relief. The Fourteenth Court of\\n\\nAppeals affirmed, finding that the district court properly maintained jurisdiction\\n\\nover misdemeanors involving “official misconduct,” including alleged misconduct\\n\\nof political candidates.\\n\\n                                           ANALYSIS\\n\\n       Our analysis begins with the question of whether Appellant’s pretrial writ\\n\\napplication is cognizable. In our prior opinion on this matter, we reiterated the\\n\\npretrial writ is meant to protect the individual’s liberty interests in avoiding trial and\\n\\nas a constitutional safeguard against overreach by the state. 2 Putting aside the merits\\n\\n\\n\\n\\n       1\\n         Specifically, Appellant contended that provisions in Article III, Section 24a of the Texas\\nConstitution and Texas Government Code Chapter 571 cabined enforcement of the violations at\\nissue to a sworn complaint to the TEC, see TEX. GOV’T CODE ANN. § 571.122, followed by an\\nadministrative review process. Id. §§ 571.124–571.129. Appellant further urged the Government\\nCode provision indicating that the Commission may “refer matters to the appropriate prosecuting\\nattorney for criminal prosecution” only upon the vote of six of eight members of the TEC indicated\\nexclusive authority and means to initiate the charge. Id. § 571.171(a). Thus, because Appellant did\\nnot receive any of these procedural protections before being criminally charged in these cases, she\\nmaintained that the prosecution was unauthorized or, alternatively, that her rights to due process\\nand due course of law had been irreparably violated.\\n       2\\n          Appellant’s claims give rise to a cognizable basis for pretrial habeas relief because they\\nimplicate both the trial court’s jurisdiction over these offenses and Appellant’s right to avoid trial\\nin the absence of prior TEC proceedings. Ex parte Charette, No. PD-0522-21, 2024 WL 4138710,\\nat *4 (Tex. Crim. App. Sept. 11, 2024), reh’g granted (Jan. 15, 2025).\\n\\x0c                                                                                  CHARETTE — 4\\n\\n\\n\\nof Appellant’s arguments as we should at this stage,3 we reaffirm that holding here.\\n\\n   I.       APPELLANT’S WRIT IS COGNIZABLE\\n\\n        We have recognized the right to habeas review where the prosecution itself\\n\\nwould be barred and the applicant’s substantive rights and judicial efficiency\\n\\ncollectively counsel in favor of immediate review. Ex parte Weise, 55 S.W.3d 617,\\n\\n620 (Tex. Crim. App. 2001).                  This would include facial attacks to the\\n\\nconstitutionality of the statute creating the offense and claims that would otherwise\\n\\n“deprive the trial court of the power to proceed.” Ex parte Lowry, 693 S.W.3d 388,\\n\\n404 (Tex. Crim. App. 2024).                While facial constitutional attacks are easily\\n\\nrecognized, other challenges going to the power of the trial court to proceed are more\\n\\nproblematic.\\n\\n        In some cases, a pretrial habeas writ will attack the trial court’s right to\\n\\nproceed under any circumstance. This would be true where the trial court lacked the\\n\\nnecessary jurisdiction to proceed. Ex parte Reedy, 282 S.W.3d 492, 502 (Tex. Crim.\\n\\nApp. 2009); Ex parte Banks, 769 S.W.2d 539, 540 (Tex. Crim. App. 1989). This\\n\\n\\n\\n        3\\n          Even when jurisdictional questions are entangled with the merits, we must first assure\\nourselves of the power of the court to act, particularly when facing a separation of powers\\nchallenge that implicates the exercise of jurisdiction that may, in itself, interfere with a\\nconstitutional assignment of power. In our system as in the federal system, “[t]he requirement that\\njurisdiction be established as a threshold matter ‘spring[s] from the nature and limits of the judicial\\npower” and is “inflexible and without exception.” Steel Co. v. Citizens for a Better Env’t, 523 U.S.\\n83, 94–95 (1988) (quoting Mansfield, C. & L. M. R. Co. v. Swan, 111 U. S. 379, 382 (1884));\\naccord Davis v. State, 956 S.W.2d 555, 559 (Tex. Crim. App. 1991).\\n\\x0c                                                                       CHARETTE — 5\\n\\n\\n\\nwould also be true where the prosecution is aimed at attacking authority completely\\n\\nassigned to another branch or department of government.\\n\\n      This case is somewhat more complex in that it turns on the circumstances of\\n\\nthe prosecution itself. Appellant contends that the TEC, an agency created by\\n\\nconstitutional amendment and assigned to the legislative department, is vested with\\n\\nexclusive (or at least primary) jurisdiction to investigate the election law violations\\n\\nat issue here. Thus, while Appellant acknowledges the authority of district and\\n\\ncounty attorneys to initiate a prosecution such as this, she contends that proceeding\\n\\nin advance of exhaustion of its process (or absent an authorizing referral) interferes\\n\\nwith the TEC’s operations and, hence, the operations of the legislative department.\\n\\nAppellant cites no evidence, however, that the charges filed against her in this\\n\\nproceeding would contradict rules or guidance provided by the TEC to herself or\\n\\nothers similarly situated so as to undermine the Commission’s authority to regulate\\n\\nelection-related activity.\\n\\n      While this Court has generally limited the pretrial writ to facial constitutional\\n\\nattacks, “certain types of as-applied claims may be raised by pretrial habeas because\\n\\nthe particular constitutional right at issue in the as-applied challenge is the type that\\n\\nwould be effectively undermined if not vindicated prior to trial.” Ex parte Perry, 483\\n\\nS.W.3d 884, 896 (Tex. Crim. App. 2016) (plurality op.). When a prosecution, by its\\n\\nvery existence and nature, would have the effect of interfering with duties assigned\\n\\x0c                                                                     CHARETTE — 6\\n\\n\\n\\nto another department of government, pretrial review is essential to avoid or at least\\n\\nmitigate the effect of the judiciary over-stepping its bounds and impeding the\\n\\nexercise of discretion assigned elsewhere. Id. That concern was detailed\\n\\ncomprehensively in the U.S. Supreme Court’s recent decision in Trump v. United\\n\\nStates where the Court stressed the need to entertain and resolve such claims before\\n\\ntrial. 603 U.S. 593, 635 (2024).\\n\\n      That problem is, if anything, more acute under our Texas Constitution, as the\\n\\noffice of the prosecutor is located in the judicial department alongside the courts\\n\\nwho preside over any cases they might bring. TEX. CONST. art. V, § 21. While these\\n\\nconsiderations will arise most obviously in cases brought directly against the Chief\\n\\nExecutive, as in the Perry and Trump cases, the “law does not discriminate between\\n\\nthe president and a private citizen.” Trump, 603 U.S. at 612 (quoting United States\\n\\nv. Burr, 25 F. Cas. 30, 34 (No. 14,692d) (CC Va. 1807)). The constitutional question\\n\\ninstead turns upon whether the process of trying of the case would conflict with\\n\\n“administration of public affairs as entrusted to” other branches of government. Id.\\n\\nat 618 (internal quotations omitted).\\n\\x0c                                                                              CHARETTE — 7\\n\\n\\n\\n         Where the applicant presents a non-frivolous 4 assertion that the prosecution\\n\\nwould result in the judicial branch interjecting itself and interfering with the exercise\\n\\nof a power assigned by the Constitution and laws to another branch or department\\n\\nof government, a pretrial writ is a proper vehicle to review the claim. Id. The case\\n\\nbefore us requires consideration of precisely these questions and is thus cognizable.\\n\\n         We now turn to the question of whether Appellant has shown that the\\n\\nprosecution would operate to interfere with the operations and authority of the TEC.\\n\\n   II.       APPELLANT HAS NOT SHOWN THAT THIS OR ANY\\n             PROSECUTION OF ELECTION LAW MATTERS WOULD\\n             INTERFERE WITH CIVIL INVESTIGATIONS BY THE TEXAS\\n             ETHICS COMMISSION\\n\\n         While Appellant’s claim presents serious jurisdiction and constitutional\\n\\nquestions, it just as surely faces serious constitutional flaws. To begin, we assume\\n\\nthe Legislature intended for its laws to be enforced. We also presume that the\\n\\nLegislature is aware of the constitutional design, by which district and county\\n\\nattorneys are empowered to pursue criminal enforcement and is no more eager than\\n\\nthe judiciary to impede on (or foreclose) enforcement authority assigned to another\\n\\nbranch or department of government.\\n\\n\\n\\n\\n         4\\n         Because the writ is by nature extraordinary, an application that is frivolous and wholly\\ninsubstantial would not be justiciable. While Appellant’s contentions are not frivolous so as to\\nforeclose cognizability by means of pretrial writ, they do confront challenges on the merits, as\\ndetailed below.\\n\\x0c                                                                     CHARETTE — 8\\n\\n\\n\\n      As further detailed below, where, as here, the Legislature has, itself,\\n\\nauthorized both criminal and civil enforcement of its law, we assume it means to\\n\\nauthorize both to proceed absent very clear indications in the text of the statute or\\n\\nthe Constitution. See Bond v. United States, 572 U.S. 844, 858 (2014); TEX. PENAL\\n\\nCODE ANN. § 1.02. We reject the categorical claim that no prosecution can be\\n\\nbrought to enforce criminal laws concerning the conduct of elections simply because\\n\\ntheir subject matter may overlap with civil jurisdiction conferred on the TEC.\\n\\nNeither do we find any basis in this record to conclude that permitting this\\n\\nprosecution would interfere with any authority assigned to the TEC.\\n\\n      A. The TEC’s Constitutional Enforcement Power Is Clear But Not Clearly\\n         Exclusive\\n\\n      The TEC is a unique agency. While many of its functions would typically be\\n\\nconsidered executive by nature, it was created directly by constitutional amendment\\n\\nand placed within the legislative department. TEX. CONST. art. III, §24a; see also\\n\\nTEX. GOV’T CODE ANN. Ch. 571. The Commission is tasked with assuring public\\n\\nconfidence in the conduct of elections, including the campaigning and financial\\n\\nbehavior of candidates and office holders. Meanwhile, county and district attorneys\\n\\n(and district courts) are authorized by Article V of the Texas Constitution and a\\n\\nvariety of statutes to pursue and preside over all manner of criminal cases, including\\n\\nbut not limited to, various election law matters.\\n\\x0c                                                                       CHARETTE — 9\\n\\n\\n\\n      We generally assume the branches of government operate separately within\\n\\ntheir respective spheres of magistry because our Constitution and the U.S.\\n\\nConstitution both demand this. See TEX. CONST. art. IV; U.S. CONST. art. IV, §4.\\n\\nThis design obviously precludes the exercise of authority by one branch or\\n\\ndepartment of government when that authority is explicitly assigned elsewhere by\\n\\nthe Constitution. But, when the Constitution does not distribute power exclusively\\n\\nto one branch of government, the question is more difficult and devolves into one of\\n\\nlegislative assignment or assent. See Youngstown Sheet and Tube v. Sawyer, 343\\n\\nU.S. 579, 637 (1952) (Jackson, J., concurring).\\n\\n      The Texas Constitution creates both the TEC and the offices of the county and\\n\\ndistrict attorneys. Nothing in either provision remotely suggests exclusivity at the\\n\\nexpense of the other. And, while it is surely within its power to do so, the Legislature\\n\\nhas not taken any action to so limit the role of prosecutors in election law cases. This\\n\\nis telling and unhelpful (if not fatal) to appellant’s argument. Id.\\n\\n      B. The Statutory Delegations to TEC Are Consistent With Parallel\\n         Criminal Enforcement\\n\\n      Chapter 571 of the Government Code expressly grants the TEC authority to\\n\\n“administer and enforce” its provisions. Appellant argues that the TEC, as part of\\n\\nthe legislative branch, must fully investigate and resolve all potential penalties\\n\\nbefore a prosecution might introduce its subject matter to the judiciary for criminal\\n\\x0c                                                                           CHARETTE — 10\\n\\n\\n\\nprosecution. 5 Yet the statutes under which Appellant was prosecuted say otherwise\\n\\nin that they authorize criminal prosecution with respect to the same activities subject\\n\\nto TEC civil enforcement.\\n\\n       “In construing a statute, we give effect to the plain meaning of its language\\n\\nunless the language is ambiguous or the plain meaning leads to absurd results that\\n\\nthe legislature could not have possibly intended.” Perry, 483 S.W.3d at 902. We\\n\\nalso presume “the statute complies with the Texas and federal constitutions; the\\n\\nentire statute is intended to be effective; a just and reasonable result is intended; a\\n\\nresult feasible of execution is intended; and public interest is favored over private\\n\\ninterest.” Dunham v. State, 666 S.W.3d 477, 484 (Tex. Crim. App. 2023). We also\\n\\ndo not generally assume that legislation is accurately interpreted as depriving\\n\\nprosecutors of their constitutional authority given the compelling governmental\\n\\ninterest in effective law enforcement. Trump v. Vance, 591 U.S. 786, 808 (2020);\\n\\nTEX. PENAL CODE §1.02. We instead presume each is free to act barring clear textual\\n\\nevidence of contrary intention and are obliged to prefer any reasonable construction\\n\\n\\n\\n\\n       5\\n         The relevant statutes include: Government Code Chapters 302, 303, 305, 572, and 2004;\\nSubchapter C, Chapter 159, Local Government Code, in connection with a county judicial officer,\\nas defined by Section 159.051, Local Government Code, who elects to file a financial statement\\nwith the commission; Title 15, Election Code [Election Code Section 251.001 et seq.; and\\nGovernment Code Sections 2152.064 and 2155.003. See Ex parte Charette, No. PD-0522-21, 2024\\nWL 4138710, at *4 (Tex. Crim. App. Sept. 11, 2024), reh'g granted (Jan. 15, 2025).\\n\\x0c                                                                     CHARETTE — 11\\n\\n\\n\\nof the statute that would avoid the ultimate constitutional question. Clark v.\\n\\nMartinez, 543 U.S. 371, 381 (2005).\\n\\n      As Appellant notes, the plain text of Government Code Section 571.172 states\\n\\nthe Ethics Commission holds the authority to “issue and enforce a cease and desist\\n\\norder to stop a violation” and to issue an “affirmative order to require compliance\\n\\nwith the laws administered and enforced by the commission.” TEX. GOV’T CODE\\n\\nANN. § 571.172.        The preceding section, Section 571.171, authorizes the\\n\\nCommission to “initiate civil enforcement actions and refer matters to the\\n\\nappropriate prosecuting attorney for criminal prosecution.” It also permits the\\n\\nTEC’s executive director, upon receiving a sworn complaint and reasonably\\n\\nbelieving that the subject has violated Chapter 36 or 39 of the Penal Code, to refer\\n\\nthe matter for criminal prosecution regardless of any pending civil investigation. Id.\\n\\n§ 571.171.\\n\\n      None of these delegations of duties is ambiguous. The plain text is clear: in\\n\\nmatters of election law, the commission is empowered to conduct investigations into\\n\\nallegations of code violations, “initiate civil enforcement actions,” and refer possible\\n\\nviolations of criminal law to district and county attorneys. The statute describes one\\n\\nmatter as civil, the other matter as criminal. The text does not purport to authorize\\n\\nthe TEC to initiate a criminal prosecution, compel such an initiation or forbid either\\n\\x0c                                                                   CHARETTE — 12\\n\\n\\n\\nthe initiation or continuation of criminal prosecutions unless or until a civil\\n\\nproceeding has first terminated.\\n\\n      To that extent, construing Government Code Sections 571.171 and 571.172\\n\\nto categorically bar prosecutions by a district attorney unless and until civil\\n\\ninvestigations and penalties have ceased or until TEC has expressly authorized\\n\\ncriminal prosecution reads language into the text, impinges upon the constitutional\\n\\nframework of this state and could lead to absurd results not supported by legislative\\n\\ntext. One case can proceed parallel to another, as criminal and civil cases often do\\n\\nin, among other settings, manslaughter and wrongful death suits and child abuse and\\n\\nparental terminations proceedings. See TEX. CIV. PRAC. & REM. CODE ANN. §\\n\\n71.006; TEX. FAM. CODE ANN. § 161.001.\\n\\n      In fact, a directly analogous situation exists in Texas with the handling of\\n\\ndriving while intoxicated (DWI) cases.          Both criminal investigations and\\n\\nprosecutions for the DWI charge and proceedings under the Administrative License\\n\\nRevocation (ALR) Program—a civil process administered by the Texas Department\\n\\nof Public Safety, a state agency within the executive branch 6—may and often do\\n\\nproceed in parallel.\\n\\n\\n\\n\\n      6\\n          TEX. TRANSP. CODE ANN. Ch. 524.\\n\\x0c                                                                                  CHARETTE — 13\\n\\n\\n\\n       C. The TEC’s Power to Refer Is Neither Unique Nor Controlling\\n\\n       Appellant stresses that Government Code § 571.171 confers authority upon\\n\\nthe TEC to refer matters to the appropriate prosecuting agency in the case of Penal\\n\\nCode violations. While the plain text of the provision at issue here authorizes but\\n\\ndoes not compel referral, this is also hardly sufficient to bar enforcement of the\\n\\nstate’s criminal laws in the absence of the exercise of that discretion. Cf. TEX. GOV’T\\n\\nCODE ANN. § 4007.001 (authorizing Texas Securities Commissioner to consider “the\\n\\nnumber and types of board employees, that would be needed to assist in the\\n\\nprosecution of the case” prior to referral).7\\n\\n       Standing alone, the authorization to refer a matter for prosecution is scant\\n\\nevidence that such a referral is a necessary pre-condition to a prosecution. Given\\n\\nthe constitutional separation of powers implications, we are reluctant to—indeed\\n\\n\\n       7\\n           Similarly, the Legislature has within the confines of our statutes created guidelines for the\\noperation of occupations, programs and services not governed by the criminal codes, but which\\nmay in the course of business come into contact with matters of criminal law. In these sections,\\nthe legislature has allocated similar referral ability, opportunity, responsibility to teachers and\\nother professionals with knowledge of potential child abuse or neglect, 9-1-1 operators, and even\\nevery person in Texas who observes a felony involving serious bodily injury. The U.S. Congress\\nhas done the same with respect to virtually every person in the United States. See TEX. FAMILY\\nCODE ANN. § 261.101; TEX. HEALTH & SAFETY CODE ANN. § 772.112; TEX. PENAL CODE ANN. §\\n38.171; and 18 U.S.C. § 4. While application of this section has been cabined by judicial\\ninterpretation to persons with some other duty it provides: “Whoever, having knowledge of the\\nactual commission of a felony cognizable by a court of the United States, conceals and does not as\\nsoon as possible make known the same to some judge or other person in . . . authority . . . shall be\\nfined under this title or imprisoned.” None of these authorizations or directives has ever been\\nconstrued as a pre-condition to the initiation of a criminal proceeding separately authorized by the\\nPenal Code.\\n\\x0c                                                                               CHARETTE — 14\\n\\n\\n\\nduty-bound not to—embrace a reading of the statute that would strip the state’s\\n\\ncounty and district attorneys of their constitutional authority to bring an otherwise\\n\\nviable criminal charge where a plain, constitutional reading of the text is available.\\n\\nRon Beal, The Art of Statutory Construction: Texas Style, 64 BAYLOR L. REV. 339,\\n\\n428 (2012). We likewise assume our Legislature, no less than us, is aware of and\\n\\nintends to legislate within the confines of our Constitution.                    See Edward J.\\n\\nDeBartolo Corp. v. Fla. Gulf Coast Bldg. & Constr. Trades Council, 485 U.S. 568,\\n\\n575 (1988) (“[Constitutional avoidance] canon “not only reflects the prudential\\n\\nconcern that constitutional issues not be needlessly confronted, but also recognizes\\n\\nthat Congress, like this Court, is bound by and swears by an oath to uphold the\\n\\nConstitution.”).\\n\\n       By way of contrast, the Legislature has explicitly provided for the type of\\n\\nabatement or primary jurisdiction urged here in other circumstances involving\\n\\npotential overlap between criminal and civil proceedings.8 When the Legislature\\n\\nintends to restrict parallel administrative and judicial enforcement of its laws, it\\n\\n\\n       8\\n          For example, the Texas Family Code’s Title 3, also known as the Juvenile Justice Code,\\nprescribes the process of investigation, referral to a first offender program, and punishment of\\nminors involved in criminal activity. This specific restraint on initiation of a criminal prosecution\\nfits the legislative design of rehabilitating, rather than punishing, the minor in question. See TEX.\\nFAM. CODE ANN. §§ 51.201–61.107; see also TEX. ATT’Y GEN. OFFICE, 2020 JUVENILE JUSTICE\\nHANDBOOK (2020). Though the cases addressed by the Juvenile Justice Code are criminal in\\nnature, the legislative text confirms, unlike the statute at issue here, no criminal case should\\nproceed unless and until its purposes are satisfied.\\n\\x0c                                                                               CHARETTE — 15\\n\\n\\n\\nknows how to do so. See TEX. LAB. CODE ANN. §§ 21.201–21.211 (addressing\\n\\nprotocol for filing and exhaustion of administrative proceedings involved in\\n\\nemployment discrimination cases). No such language appears in the statutory text\\n\\nhere and reading it into the statute would create an otherwise avoidable constitutional\\n\\nconflict.\\n\\n       For all of these reasons, we decline Appellant’s invitation to read the referral\\n\\nprovision as a necessary precondition to criminal enforcement.\\n\\n   III.     MOTION TO DISMISS\\n\\n      The State brings to our attention recent legislation concerning the right of\\n\\nprosecutors to proceed in the absence of any referral from the TEC, urging that it\\n\\napplies retroactively so as to moot this controversy. 9 Appellant responds, urging\\n\\nthat although the plain text of Texas Government Code § 23.002 authorizes the law\\n\\nto apply retroactively, we ought to disregard such application as it presents\\n\\nconstitutional questions concerning its retroactive application. While we are grateful\\n\\nto the State and to Appellant for bringing this development to our attention, we see\\n\\nno need to opine on the constitutional questions Appellant raises in view of our\\n\\ndisposition above. See In re B.L.D., 113 S.W.3d 340, 349 (Tex. 2003); accord\\n\\n\\n       9\\n         “Unless expressly provided otherwise, the exhaustion of civil, including administrative,\\nremedies is not a prerequisite to the vesting in a trial court of subject matter jurisdiction over a\\ncriminal action for which the trial court would otherwise have jurisdiction under other law.” TEX.\\nGOV’T CODE ANN. § 23.002.\\n\\x0c                                                                    CHARETTE — 16\\n\\n\\n\\nAshwander v. Tenn. Valley Auth., 297 U.S. 288, 347 (1936) (Brandeis, J.,\\n\\nconcurring) (“If a case can be decided on either of two grounds, one involving a\\n\\nconstitutional question, the other a question of statutory construction or general law,\\n\\nthe Court will decide only the latter.”).\\n\\n                                   CONCLUSION\\n\\n      While we find Appellant’s application for a pretrial writ of habeas corpus to\\n\\nbe cognizable, she has failed to demonstrate her entitlement to relief. For these\\n\\nreasons, the Court withdraws its prior opinion reversing the court of appeals and\\n\\ninstead affirms its judgment.\\n\\n\\n\\n\\nDelivered: August 20, 2025\\n\\nPublish\\n\\x0c\", 'metadata': {'case_name': None, 'court': None, 'date_filed': None, 'citation': None, 'docket_number': None, 'url': '/opinion/10659480/charette-ex-parte-robbie-gail-v-the-state-of-texas/'}}\n",
            "Saved 1000 cases to courtlistener_cases.jsonl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "API_BASE = \"https://www.courtlistener.com/api/rest/v4\"\n",
        "TOKEN = #os.getenv(\"COURTLISTENER_API_TOKEN\")\n",
        "\n",
        "headers = {\"Authorization\": f\"Token {TOKEN}\"} if TOKEN else {}\n",
        "\n",
        "def ingest_courtlistener(max_records=1000):\n",
        "    results, count = [], 0\n",
        "    url = f\"{API_BASE}/opinions/\"\n",
        "\n",
        "    while url and count < max_records:\n",
        "        resp = requests.get(url, headers=headers, timeout=60)\n",
        "        #print(resp)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        #print(data)\n",
        "        for item in data.get(\"results\", []):\n",
        "            if count >= max_records:\n",
        "                break\n",
        "            rec = {\n",
        "                \"id\": f\"cl:{item.get('id')}\",\n",
        "                \"source\": \"courtlistener\",\n",
        "                \"doc_type\": \"case\",\n",
        "                \"text\": item.get(\"plain_text\") or item.get(\"html\"),\n",
        "                \"metadata\": {\n",
        "                    \"case_name\": item.get(\"caseName\") or item.get(\"case_name\"),\n",
        "                    \"court\": item.get(\"court\", {}).get(\"name\"),\n",
        "                    \"date_filed\": item.get(\"dateFiled\"),\n",
        "                    \"citation\": item.get(\"citation\"),\n",
        "                    \"docket_number\": item.get(\"docket_number\"),\n",
        "                    \"url\": item.get(\"absolute_url\"),\n",
        "                }\n",
        "            }\n",
        "            results.append(rec)\n",
        "            count += 1\n",
        "        url = data.get(\"next\")\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  court_listner_data = ingest_courtlistener()\n",
        "  print(len(court_listner_data))\n",
        "  print(court_listner_data[0])\n",
        "  output_file = \"courtlistener_cases.jsonl\"\n",
        "  with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      for case in court_listner_data:\n",
        "          f.write(json.dumps(case) + \"\\n\")\n",
        "\n",
        "  print(f\"Saved {len(court_listner_data)} cases to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from langchain.schema import Document\n",
        "\n",
        "def load_cuad_json(cuad_json_path: str):\n",
        "    \"\"\"\n",
        "    Load CUAD JSON and return a list of LangChain Documents.\n",
        "    Each Document = clause text + metadata (clause_type, risk, contract_id).\n",
        "    Assumes the JSON structure provided in the user's example.\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "\n",
        "    with open(cuad_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Assuming the top level is a dictionary with a 'data' key containing a list of documents\n",
        "    if not isinstance(data, dict) or \"data\" not in data or not isinstance(data[\"data\"], list):\n",
        "        raise TypeError(\"Unexpected JSON structure. Expected a dictionary with a 'data' key containing a list.\")\n",
        "\n",
        "    for document_data in data[\"data\"]:\n",
        "        if not isinstance(document_data, dict):\n",
        "            logging.warning(f\"Expected document data to be a dictionary, but got {type(document_data)}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        contract_id = document_data.get(\"title\", \"Unknown\")\n",
        "        paragraphs = document_data.get(\"paragraphs\", [])\n",
        "\n",
        "        if not isinstance(paragraphs, list):\n",
        "            logging.warning(f\"Expected 'paragraphs' to be a list in document {contract_id}, but got {type(paragraphs)}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        for paragraph in paragraphs:\n",
        "            if not isinstance(paragraph, dict):\n",
        "                logging.warning(f\"Expected paragraph to be a dictionary in document {contract_id}, but got {type(paragraph)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            qas = paragraph.get(\"qas\", [])\n",
        "\n",
        "            if not isinstance(qas, list):\n",
        "                logging.warning(f\"Expected 'qas' to be a list in document {contract_id}, paragraph, but got {type(qas)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            for qa in qas:\n",
        "                if not isinstance(qa, dict):\n",
        "                    logging.warning(f\"Expected qa to be a dictionary in document {contract_id}, paragraph, but got {type(qa)}. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                answers = qa.get(\"answers\", [])\n",
        "                clause_type = qa.get(\"question\", \"Unknown Clause Type\")\n",
        "\n",
        "                if not isinstance(answers, list):\n",
        "                     logging.warning(f\"Expected 'answers' to be a list in document {contract_id}, paragraph, qa, but got {type(answers)}. Skipping.\")\n",
        "                     continue\n",
        "\n",
        "                for answer in answers:\n",
        "                    if not isinstance(answer, dict):\n",
        "                         logging.warning(f\"Expected answer to be a dictionary in document {contract_id}, paragraph, qa, but got {type(answer)}. Skipping.\")\n",
        "                         continue\n",
        "\n",
        "                    clause_text = answer.get(\"text\", \"\").strip()\n",
        "\n",
        "                    if clause_text:  # only keep non-empty\n",
        "                        documents.append(\n",
        "                            Document(\n",
        "                                page_content=clause_text,\n",
        "                                metadata={\n",
        "                                    \"contract_id\": contract_id,\n",
        "                                    \"clause_type\": clause_type,\n",
        "                                    \"clause_text\": clause_text,\n",
        "\n",
        "                                }\n",
        "                            )\n",
        "                        )\n",
        "    return documents\n",
        "\n",
        "\n",
        "def save_as_jsonl(documents, output_path: str):\n",
        "    import jsonlines\n",
        "    with jsonlines.open(output_path, mode=\"w\") as writer:\n",
        "        for doc in documents:\n",
        "            writer.write({\n",
        "                \"text\": doc.page_content,\n",
        "                \"metadata\": doc.metadata\n",
        "            })\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    CUAD_JSON_PATH = \"/content/drive/MyDrive/Colab Notebooks/RAG_legal/CUAD_v1/CUAD_v1.json\"\n",
        "    OUTPUT_JSONL = \"cuad_preprocessed.jsonl\"\n",
        "\n",
        "    if not os.path.exists(CUAD_JSON_PATH):\n",
        "        raise FileNotFoundError(f\"Could not find {CUAD_JSON_PATH}. Check your path!\")\n",
        "\n",
        "    docs = load_cuad_json(CUAD_JSON_PATH)\n",
        "    print(f\"Loaded {len(docs)} clauses from CUAD.\")\n",
        "    if docs:\n",
        "        print(f\"Sample document: {docs[0]}\")\n",
        "    else:\n",
        "        print(\"No documents were loaded.\")\n",
        "\n",
        "\n",
        "    # Save for later reuse\n",
        "    save_as_jsonl(docs, OUTPUT_JSONL)\n",
        "    print(f\"Saved preprocessed dataset to {OUTPUT_JSONL}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THuGw0RlM12q",
        "outputId": "e2506380-49f4-4863-c89e-0dfda0d7a118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 13823 clauses from CUAD.\n",
            "Sample document: page_content='DISTRIBUTOR AGREEMENT' metadata={'contract_id': 'LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT', 'clause_type': 'Highlight the parts (if any) of this contract related to \"Document Name\" that should be reviewed by a lawyer. Details: The name of the contract', 'clause_text': 'DISTRIBUTOR AGREEMENT'}\n",
            "Saved preprocessed dataset to cuad_preprocessed.jsonl.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "US code data ingestion"
      ],
      "metadata": {
        "id": "o5fgbak7Q81O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "USCODE_DIR = \"/content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code\"\n",
        "OUTPUT_FILE = \"uscode_preprocessed.jsonl\"\n",
        "\n",
        "def parse_uscode_file(file_path):\n",
        "    \"\"\"Parse a US Code XML file with namespaces\"\"\"\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Handle namespaces dynamically\n",
        "    ns = {\"uslm\": root.tag.split(\"}\")[0].strip(\"{\")}\n",
        "\n",
        "    title_num = root.attrib.get(\"num\", \"Unknown\")\n",
        "    title_name = root.attrib.get(\"name\", f\"Title {title_num}\")\n",
        "\n",
        "    docs = []\n",
        "    for section in root.findall(\".//uslm:section\", ns):\n",
        "        sec_num = section.findtext(\"uslm:num\", default=\"\", namespaces=ns)\n",
        "        sec_heading = section.findtext(\"uslm:heading\", default=\"\", namespaces=ns)\n",
        "\n",
        "        # Extract full section content (paragraphs, subparagraphs, etc.)\n",
        "        content_el = section.find(\"uslm:content\", ns)\n",
        "        sec_text = \"\"\n",
        "        if content_el is not None:\n",
        "            sec_text = \" \".join([t.strip() for t in content_el.itertext() if t.strip()])\n",
        "\n",
        "        if sec_text:\n",
        "            doc = {\n",
        "                \"title_num\": title_num,\n",
        "                \"title_name\": title_name,\n",
        "                \"section_num\": sec_num,\n",
        "                \"heading\": sec_heading,\n",
        "                \"content\": sec_text\n",
        "            }\n",
        "            docs.append(doc)\n",
        "\n",
        "    return docs\n",
        "\n",
        "\n",
        "def ingest_uscode(data_dir, output_file):\n",
        "    all_docs = []\n",
        "    xml_files = glob.glob(os.path.join(data_dir, \"*.xml\"))\n",
        "\n",
        "    print(f\"Found {len(xml_files)} XML files in {data_dir}\")\n",
        "\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for xml_file in xml_files:\n",
        "            try:\n",
        "                docs = parse_uscode_file(xml_file)\n",
        "                for d in docs:\n",
        "                    f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n",
        "                all_docs.extend(docs)\n",
        "                print(f\"Processed {xml_file} -> {len(docs)} sections\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing {xml_file}: {e}\")\n",
        "\n",
        "    print(f\"\\nTotal documents ingested: {len(all_docs)}\")\n",
        "    print(f\"Saved to {output_file}\")\n",
        "    return all_docs\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ingest_uscode(USCODE_DIR, OUTPUT_FILE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBRJawudcQSF",
        "outputId": "8281d572-3ab8-496f-bad7-3b9c337ee110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 XML files in /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc01.xml -> 35 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc07.xml -> 873 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc05.xml -> 281 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc02.xml -> 442 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc15.xml -> 726 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc11.xml -> 64 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc17.xml -> 27 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc26.xml -> 330 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc29.xml -> 196 sections\n",
            "✅ Processed /content/drive/MyDrive/Colab Notebooks/RAG_legal/US_Code/usc42.xml -> 1499 sections\n",
            "\n",
            "Total documents ingested: 4473\n",
            "Saved to uscode_preprocessed.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding and chunking and Fiass Indexing"
      ],
      "metadata": {
        "id": "RhNoPTM8cLOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math\n",
        "from typing import List, Dict\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import numpy as np\n",
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "\n",
        "# --------- CONFIG ---------\n",
        "GOOGLE_API_KEY = \"api-key\"\n",
        "EMBED_MODEL = \"models/embedding-001\"\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 150\n",
        "\n",
        "#  preprocessed files\n",
        "COURTLISTENER_JSONL = \"courtlistener_cases.jsonl\"\n",
        "CUAD_JSONL          = \"cuad_preprocessed.jsonl\"\n",
        "USCODE_JSONL        = \"uscode_preprocessed.jsonl\"\n",
        "\n",
        "OUT_DIR = \"indices\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# --------- HELPERS ---------\n",
        "def read_jsonl(path: str) -> List[Dict]:\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            rows.append(json.loads(line))\n",
        "    return rows\n",
        "\n",
        "def to_documents(rows: List[Dict], source_name: str) -> List[Document]:\n",
        "    docs = []\n",
        "    for r in rows:\n",
        "        # Normalize common shapes from your saved files\n",
        "        if source_name == \"courtlistener\":\n",
        "            text = r.get(\"text\") or \"\"\n",
        "            md = r.get(\"metadata\", {})\n",
        "            md.update({\"source\": \"courtlistener\", \"id\": r.get(\"id\")})\n",
        "        elif source_name == \"cuad\":\n",
        "            text = r.get(\"text\") or r.get(\"page_content\") or \"\"\n",
        "            md = r.get(\"metadata\", {})\n",
        "            md.update({\"source\": \"cuad\"})\n",
        "        elif source_name == \"uscode\":\n",
        "\n",
        "            text = r.get(\"content\") or r.get(\"text\") or \"\"\n",
        "            md = {\n",
        "                \"source\": \"uscode\",\n",
        "                \"title_num\": r.get(\"title_num\"),\n",
        "                \"title_name\": r.get(\"title_name\"),\n",
        "                \"section_num\": r.get(\"section_num\"),\n",
        "                \"heading\": r.get(\"heading\"),\n",
        "            }\n",
        "        else:\n",
        "            text, md = \"\", {}\n",
        "\n",
        "        text = \" \".join(str(text).split())\n",
        "        if not text:\n",
        "            continue\n",
        "        docs.append(Document(page_content=text, metadata=md))\n",
        "    return docs\n",
        "\n",
        "def chunk_documents(docs: List[Document]) -> List[Document]:\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP, separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
        "    )\n",
        "    chunks = []\n",
        "    for d in docs:\n",
        "        for chunk in splitter.split_text(d.page_content):\n",
        "            chunks.append(Document(page_content=chunk, metadata=d.metadata))\n",
        "    return chunks\n",
        "\n",
        "def build_faiss_cosine(docs: List[Document], embedder: GoogleGenerativeAIEmbeddings) -> FAISS:\n",
        "    # Embed\n",
        "    texts = [d.page_content for d in docs]\n",
        "    vecs = np.array(embedder.embed_documents(texts), dtype=\"float32\")\n",
        "\n",
        "    # L2 normalize (cosine)\n",
        "    norms = np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-12\n",
        "    vecs = vecs / norms\n",
        "\n",
        "    # Build FAISS IP index\n",
        "    dim = vecs.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(vecs)\n",
        "\n",
        "    #  docstore\n",
        "    docstore = InMemoryDocstore()\n",
        "    store = FAISS(\n",
        "        embedding_function=embedder,\n",
        "        index=index,\n",
        "        docstore=docstore,\n",
        "        index_to_docstore_id={}\n",
        "    )\n",
        "\n",
        "    for i, d in enumerate(docs):\n",
        "        doc_id = str(i)\n",
        "        store.docstore.add({doc_id: d})\n",
        "        store.index_to_docstore_id[i] = doc_id\n",
        "\n",
        "    return store\n",
        "\n",
        "def save_store(store: FAISS, path: str):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    store.save_local(path)\n",
        "\n",
        "def main():\n",
        "    if not GOOGLE_API_KEY:\n",
        "        raise EnvironmentError(\"Set GOOGLE_API_KEY environment variable.\")\n",
        "\n",
        "\n",
        "    embedder = GoogleGenerativeAIEmbeddings(model=EMBED_MODEL, google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "\n",
        "    # ---- CourtListener ----\n",
        "    try:\n",
        "        cl_rows = read_jsonl(COURTLISTENER_JSONL)\n",
        "        cl_docs = to_documents(cl_rows, \"courtlistener\")\n",
        "        cl_chunks = chunk_documents(cl_docs)\n",
        "        cl_store = build_faiss_cosine(cl_chunks, embedder)\n",
        "        save_store(cl_store, os.path.join(OUT_DIR, \"courtlistener\"))\n",
        "        print(f\"CourtListener index built with {cl_store.index.ntotal} chunks\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"CourtListener JSONL file not found: {COURTLISTENER_JSONL}. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error building CourtListener index: {e}\")\n",
        "\n",
        "\n",
        "    # ---- CUAD ----\n",
        "    try:\n",
        "        cuad_rows = read_jsonl(CUAD_JSONL)\n",
        "        cuad_docs = to_documents(cuad_rows, \"cuad\")\n",
        "        cuad_chunks = chunk_documents(cuad_docs)\n",
        "        cuad_store = build_faiss_cosine(cuad_chunks, embedder)\n",
        "        save_store(cuad_store, os.path.join(OUT_DIR, \"cuad\"))\n",
        "        print(f\"CUAD index built with {cuad_store.index.ntotal} chunks\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"CUAD JSONL file not found: {CUAD_JSONL}. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error building CUAD index: {e}\")\n",
        "\n",
        "\n",
        "    # ---- U.S. Code ----\n",
        "    try:\n",
        "        usc_rows = read_jsonl(USCODE_JSONL)\n",
        "        usc_docs = to_documents(usc_rows, \"uscode\")\n",
        "        usc_chunks = chunk_documents(usc_docs)\n",
        "        usc_store = build_faiss_cosine(usc_chunks, embedder)\n",
        "        save_store(usc_store, os.path.join(OUT_DIR, \"uscode\"))\n",
        "        print(f\"U.S. Code index built with {usc_store.index.ntotal} chunks\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"U.S. Code JSONL file not found: {USCODE_JSONL}. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error building U.S. Code index: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KOeY0aDG603",
        "outputId": "cf76de35-f947-47d5-ca03-662c63d659ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CourtListener index built with 23203 chunks\n",
            "✅ CUAD index built with 14204 chunks\n",
            "✅ U.S. Code index built with 5209 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieval and Generation"
      ],
      "metadata": {
        "id": "BQuOKs3N6S0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "from datetime import datetime\n",
        "\n",
        "SESSION_ID = datetime.utcnow().strftime(\"%Y%m%dT%H%M%S\")\n",
        "LOG_FILE = f\"conversation_{SESSION_ID}.jsonl\"\n",
        "\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "LOG_FILE = os.path.join(\"logs\", LOG_FILE)\n",
        "\n",
        "GOOGLE_API_KEY = \"api-key\"\n",
        "EMBED_MODEL = \"models/embedding-001\"\n",
        "CHAT_MODEL  = \"gemini-2.5-flash\"\n",
        "\n",
        "INDEX_ROOT = \"indices\"\n",
        "K_PER_SOURCE = 6\n",
        "TOPK_GLOBAL  = 8\n",
        "\n",
        "# ---------- Loaders ----------\n",
        "def load_store(subdir: str, embedder: GoogleGenerativeAIEmbeddings) -> FAISS:\n",
        "    path = os.path.join(INDEX_ROOT, subdir)\n",
        "    return FAISS.load_local(path, embedder, allow_dangerous_deserialization=True)\n",
        "\n",
        "def load_all() -> Dict[str, FAISS]:\n",
        "    embedder = GoogleGenerativeAIEmbeddings(model=EMBED_MODEL, google_api_key=GOOGLE_API_KEY)\n",
        "    stores = {\n",
        "        \"courtlistener\": load_store(\"courtlistener\", embedder),\n",
        "        \"cuad\": load_store(\"cuad\", embedder),\n",
        "        \"uscode\": load_store(\"uscode\", embedder),\n",
        "    }\n",
        "    return stores, embedder\n",
        "\n",
        "# ---------- Gemini-based Router ----------\n",
        "def gemini_route(query: str, llm: ChatGoogleGenerativeAI) -> List[str]:\n",
        "    \"\"\"Use Gemini to classify query into sources. Returns list of target sources.\"\"\"\n",
        "\n",
        "    classification_prompt = f\"\"\"\n",
        "    You are a router for a Legal Research Assistant.\n",
        "    Decide which knowledge source(s) the question should query:\n",
        "    - \"courtlistener\" → for precedents, case law, judicial opinions.\n",
        "    - \"uscode\" → for statutes, laws, federal titles/sections.\n",
        "    - \"cuad\" → for contract clauses, risks, obligations.\n",
        "\n",
        "    The user query is:\n",
        "    \"{query}\"\n",
        "\n",
        "    Respond ONLY with a comma-separated list of sources (e.g., \"courtlistener, uscode\").\n",
        "    If unsure, say \"uncertain\".\n",
        "    \"\"\"\n",
        "\n",
        "    resp = llm.invoke(classification_prompt)\n",
        "    text = resp.content.strip().lower()\n",
        "\n",
        "    if \"uncertain\" in text or not text:\n",
        "        return []\n",
        "    sources = [s.strip() for s in text.split(\",\") if s.strip() in [\"courtlistener\", \"uscode\", \"cuad\"]]\n",
        "    return sources\n",
        "\n",
        "# ---------- Keyword Fallback Router ----------\n",
        "def keyword_route(query: str) -> List[str]:\n",
        "    q = query.lower()\n",
        "    if any(w in q for w in [\"statute\", \"u.s. code\", \"title \", \"usc \", \"section \", \"§\"]):\n",
        "        return [\"uscode\"]\n",
        "    if any(w in q for w in [\"clause\", \"contract\", \"agreement\", \"termination\", \"indemnification\", \"confidentiality\"]):\n",
        "        return [\"cuad\"]\n",
        "    if any(w in q for w in [\"precedent\", \"case\", \"opinion\", \"appeals\", \"holding\", \"binding\", \"citation\"]):\n",
        "        return [\"courtlistener\"]\n",
        "    return [\"courtlistener\", \"cuad\", \"uscode\"]\n",
        "\n",
        "# ---------- Retrieval ----------\n",
        "def normalize_scores(pairs: List[Tuple[Document, float]]) -> List[Tuple[Document, float]]:\n",
        "    out = []\n",
        "    for d, s in pairs:\n",
        "        sim = float(max(0.0, min(1.0, s))) if s is not None else 0.0\n",
        "        out.append((d, sim))\n",
        "    return out\n",
        "\n",
        "def retrieve(stores: Dict[str, FAISS], query: str, targets: List[str]) -> List[Tuple[Document, float]]:\n",
        "    hits: List[Tuple[Document, float]] = []\n",
        "    for name in targets:\n",
        "        store = stores[name]\n",
        "        pairs = store.similarity_search_with_score(query, k=K_PER_SOURCE)\n",
        "        hits.extend(normalize_scores(pairs))\n",
        "    hits.sort(key=lambda x: x[1], reverse=True)\n",
        "    seen, merged = set(), []\n",
        "    for d, s in hits:\n",
        "        key = (d.page_content[:200], tuple(sorted(d.metadata.items())))\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        merged.append((d, s))\n",
        "        if len(merged) >= TOPK_GLOBAL:\n",
        "            break\n",
        "    return merged\n",
        "\n",
        "# ---------- Prompt ----------\n",
        "ANSWER_PROMPT = \"\"\"You are a Legal Research & Contract Analysis assistant.\n",
        "Use ONLY the provided context to answer. Cite each point with [source] using the metadata.\n",
        "If something is unclear or missing, say so.\n",
        "\n",
        "Conversation so far (last 3 turns only):\n",
        "{question}\n",
        "\n",
        "Relevant context:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "- Summarize clearly and conservatively.\n",
        "- Distinguish statutes vs. cases vs. contract clauses.\n",
        "- Include citations like: (U.S. Code Title {{title_num}} §{{section_num}})\n",
        "  or (Case: {{case_name}}, Court, Date)\n",
        "  or (Clause: {{clause_type}}, Contract {{contract_id}}).\n",
        "- Do NOT provide legal advice; only informational summaries with sources.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def make_context(chunks: List[Tuple[Document, float]]) -> str:\n",
        "    lines = []\n",
        "    for d, s in chunks:\n",
        "        md = d.metadata or {}\n",
        "        src = md.get(\"source\", \"?\")\n",
        "        tag = \"[SOURCE]\" # Default tag\n",
        "\n",
        "        if src == \"uscode\":\n",
        "            title_num = md.get('title_num', 'N/A')\n",
        "            section_num = md.get('section_num', 'N/A')\n",
        "            heading = md.get('heading', 'N/A')\n",
        "            tag = f\"[USC T{title_num} §{section_num} – {heading}]\"\n",
        "        elif src == \"courtlistener\":\n",
        "            case_name = md.get('case_name', 'N/A')\n",
        "            court = md.get('court', 'N/A')\n",
        "            date_filed = md.get('date_filed', 'N/A')\n",
        "            url = md.get('url', '#')\n",
        "            tag = f\"[CASE {case_name} | {court} | {date_filed} | {url}]\"\n",
        "        elif src == \"cuad\":\n",
        "            clause_type = md.get('clause_type', 'N/A')\n",
        "            contract_id = md.get('contract_id', 'N/A')\n",
        "            tag = f\"[CLAUSE {clause_type} | contract {contract_id}]\"\n",
        "\n",
        "\n",
        "        lines.append(f\"{tag} (score={s:.3f})\\n{d.page_content}\\n\")\n",
        "    return \"\\n---\\n\".join(lines)\n",
        "\n",
        "\n",
        "def answer(query: str, history: list = None) -> str:\n",
        "    if not GOOGLE_API_KEY:\n",
        "        raise EnvironmentError(\"Set GOOGLE_API_KEY before running.\")\n",
        "\n",
        "    stores, _ = load_all()\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=CHAT_MODEL,\n",
        "        temperature=0.2,\n",
        "        google_api_key=GOOGLE_API_KEY\n",
        "    )\n",
        "\n",
        "    # ---- Hybrid Routing ----\n",
        "    targets = gemini_route(query, llm)\n",
        "    if targets:\n",
        "        print(f\"[Router] Gemini classified → {targets}\")\n",
        "    else:\n",
        "        targets = keyword_route(query)\n",
        "        print(f\"[Router] Gemini uncertain → fallback to keyword router → {targets}\")\n",
        "\n",
        "    # ---- Retrieve & Build Context ----\n",
        "    chunks = retrieve(stores, query, targets)\n",
        "    context = make_context(chunks)\n",
        "\n",
        "        # ---- Build conversation context (cap last 3 turns) ----\n",
        "    conversation = \"\"\n",
        "    if history:\n",
        "        trimmed_history = history[-3:]  # keep only last 3 turns\n",
        "        for user_msg, bot_msg in trimmed_history:\n",
        "            conversation += f\"User: {user_msg}\\nAssistant: {bot_msg}\\n\"\n",
        "    conversation += f\"User: {query}\\nAssistant:\"\n",
        "\n",
        "\n",
        "    # ---- Answer Generation ----\n",
        "    prompt = ANSWER_PROMPT.format(question=conversation, context=context)\n",
        "    resp = llm.invoke(prompt)\n",
        "    # ---- Log full conversation ----\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        \"query\": query,\n",
        "        \"response\": resp.content,\n",
        "        \"history\": history if history else [],\n",
        "        \"retrieved_sources\": targets\n",
        "    }\n",
        "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(log_entry) + \"\\n\")\n",
        "\n",
        "    return resp.content\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    qs = [\n",
        "        \"What are key federal statutes on non-compete agreements?\",\n",
        "        \"Find precedents on arbitration clauses in employment agreements.\",\n",
        "        \"Summarize risks in a termination clause of a contract.\"\n",
        "    ]\n",
        "    for q in qs:\n",
        "        print(\"=\"*80)\n",
        "        print(\"Q:\", q)\n",
        "        print(\"-\"*80)\n",
        "        print(answer(q))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l61T6mz6R56",
        "outputId": "48535be7-5a47-4c77-96d7-579f9c57ec9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3871831950.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  SESSION_ID = datetime.utcnow().strftime(\"%Y%m%dT%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Q: What are key federal statutes on non-compete agreements?\n",
            "--------------------------------------------------------------------------------\n",
            "[Router] Gemini classified → ['uscode']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3871831950.py:186: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": datetime.utcnow().isoformat(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided context, there are no specific federal statutes directly addressing or defining \"non-compete agreements.\"\n",
            "\n",
            "The context mentions:\n",
            "*   Provisions related to antitrust laws, stating that certain chapters do not repeal, modify, or supersede them [USC TUnknown §§ 1224] and do not convey antitrust immunity or create defenses to antitrust actions [USC TUnknown §§ 12007]. These sections define \"antitrust laws\" as those set forth in section 12 of title 15 [USC TUnknown §§ 12007].\n",
            "*   Clarification of remedies for federal employees, former federal employees, or applicants for federal employment, stating that nothing in a particular title shall prevent them from exercising any right otherwise available under U.S. laws [USC TUnknown §“SEC. 205. – CLARIFICATION OF REMEDIES.].\n",
            "\n",
            "However, none of these snippets explicitly define, regulate, or list key federal statutes on non-compete agreements. The information regarding antitrust laws is a general statement about their applicability, not a specific regulation of non-competes.\n",
            "================================================================================\n",
            "Q: Find precedents on arbitration clauses in employment agreements.\n",
            "--------------------------------------------------------------------------------\n",
            "[Router] Gemini classified → ['courtlistener']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3871831950.py:186: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": datetime.utcnow().isoformat(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are precedents on arbitration clauses, drawing solely from the provided context:\n",
            "\n",
            "**General Principles of Arbitration Agreements:**\n",
            "*   Arbitration agreements are governed by the Federal Arbitration Act (FAA) (U.S. Code Title 9 §§ 1–16) [CASE /opinion/10658506/riley-v-national-railroad-passenger-corporation/].\n",
            "*   The FAA reflects a liberal federal policy favoring arbitration agreements, creating a body of federal substantive law of arbitrability (Case: Moses H. Cone Mem. Hosp. v. Mercury Constr. Corp., 460 U.S. 1, 24 (1983)) [CASE /opinion/10658506/riley-v-national-railroad-passenger-corporation/].\n",
            "*   Congress's intent with the FAA was to move parties to an arbitrable dispute into arbitration quickly and easily (Case: Snap-on Tools Corp. v. Mason, 18 F.3d 1261, 1263 (5th Cir. 1994)) [CASE /opinion/10658506/riley-v-national-railroad-passenger-corporation/].\n",
            "*   Under the FAA, arbitration agreements are \"valid, irrevocable, and enforceable, save upon such grounds as exist at law or in equity for the revocation of any contract\" (U.S. Code Title 9 § 2) [CASE /opinion/10659300/trawick-v-netcredit-loan-services-llc/].\n",
            "*   A court will order parties to arbitrate if it determines that an agreement to arbitrate the controversy exists [CASE /opinion/10658781/cruz-v-tapestry-inc-ca21/].\n",
            "*   A dispute must be sent to arbitration if: 1) the parties formed a valid, written agreement to arbitrate; 2) the dispute falls within the scope of that agreement; and 3) a party refuses to arbitrate (Case: Zurich Am. Ins. Co. v. Watts Indus., Inc., 417 F.3d 682, 687 (7th Cir. 2005)) [CASE /opinion/10659300/trawick-v-netcredit-loan-services-llc/].\n",
            "*   Arbitration agreements are often intended to be broadly interpreted to include all disputes and claims relating to or arising out of the agreement, service, or website, to the fullest extent permitted by law [CASE /opinion/10659230/colombia-v-experian-information-solutions-inc/].\n",
            "*   The party opposing arbitration bears the burden of demonstrating that the arbitration agreement is unenforceable (Case: Green Tree Fin. Corp.-Ala. v. Randolph, 531 U.S. 79, 91 (2000)) [CASE /opinion/10659300/trawick-v-netcredit-loan-services-llc/].\n",
            "\n",
            "**Arbitration Clauses in Employment Agreements:**\n",
            "*   An employee seeking to enforce an arbitration agreement against a company’s agents or employees as third-party beneficiaries would need to show that the nonsignatory actually accepted a benefit under the agreement [CASE /opinion/10659381/mendoza-v-movement-mortgage-llc/].\n",
            "*   The plain language of an arbitration agreement may provide a significant benefit to a company’s related entities without any reciprocal benefit to the employee [CASE /opinion/10659381/mendoza-v-movement-mortgage-llc/].\n",
            "\n",
            "**Challenges to Enforceability (Unconscionability):**\n",
            "*   An arbitration provision requiring parties to split arbitration costs and post fees in advance was found unconscionable, even if the employer offered to modify the agreement and bear the cost (Case: Martinez v. Master Prot. Corp., 118 Cal. App. 4th 107, 116–17 (2004)) [CASE /opinion/10659381/mendoza-v-movement-mortgage-llc/].\n",
            "*   Unconscionability is evaluated based on the text of the arbitration agreement, not its practical effect, even if terms cannot be enforced as written due to statutory protections (Case: Samaniego v. Empire Today LLC, 205 Cal. App. 4th 1138, 1147 (2012)) [CASE /opinion/10659381/mendoza-v-movement-mortgage-llc/].\n",
            "================================================================================\n",
            "Q: Summarize risks in a termination clause of a contract.\n",
            "--------------------------------------------------------------------------------\n",
            "[Router] Gemini classified → ['cuad']\n",
            "Risks in a termination clause of a contract can include:\n",
            "\n",
            "*   **Post-Termination Obligations**: Parties may be subject to ongoing obligations after the termination or expiration of an agreement, such as post-termination transition, payment, transfer of intellectual property, wind-down activities, or last-buy commitments (Clause: Post-Termination Services, Contract AURASYSTEMSINC_06_16_2010-EX-10.25-STRATEGIC ALLIANCE AGREEMENT).\n",
            "*   **Termination Due to Change of Control**: One party may have the right to terminate the agreement, or require consent or notice, if the counterparty undergoes a change of control event, such as a merger, stock sale, transfer of substantially all assets or business, or assignment by operation of law (Clause: Change Of Control, Contract ENTERTAINMENTGAMINGASIAINC_02_15_2005-EX-10.5-DISTRIBUTOR AGREEMENT; Clause: Change Of Control, Contract KitovPharmaLtd_20190326_20-F_EX-4.15_11584449_EX-4.15_Manufacturing Agreement).\n",
            "*   **Termination for Non-Compliance with Specific Requirements**: A party may have the right to terminate the agreement if the other party fails to meet certain contractual requirements, including:\n",
            "    *   Maintaining required insurance (Clause: Insurance, Contract JOINTCORP_09_19_2014-EX-10.15-FRANCHISE AGREEMENT).\n",
            "    *   Fulfilling minimum commitment obligations (Clause: Minimum Commitment, Contract JOINTCORP_09_19_2014-EX-10.15-FRANCHISE AGREEMENT).\n",
            "    *   Adhering to non-disparagement clauses (Clause: Non-Disparagement, Contract JOINTCORP_09_19_2014-EX-10.15-FRANCHISE AGREEMENT).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3871831950.py:186: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": datetime.utcnow().isoformat(),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "async def chat_fn(message, history):\n",
        "    try:\n",
        "\n",
        "        response = answer(message)\n",
        "    except Exception as e:\n",
        "        response = f\"⚠️ Error: {str(e)}\"\n",
        "    return response\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ⚖️ RAG Legal Assistant Chatbot\\nAsk questions about case law, statutes, or contracts.\")\n",
        "\n",
        "    chatbot = gr.Chatbot(height=500)\n",
        "    msg = gr.Textbox(label=\"Enter your legal question\")\n",
        "\n",
        "    async def respond(message, chat_history):\n",
        "      # chat_fn is async, so await here\n",
        "      bot_msg = await chat_fn(message, chat_history)   # pass history\n",
        "      chat_history.append((message, bot_msg))\n",
        "      return \"\", chat_history\n",
        "\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "8GvgO0USM8V1",
        "outputId": "c8fc9c2b-36c7-40a6-bfff-bf36a299cfb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1188541530.py:15: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://44fb04e7d5db6d233c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://44fb04e7d5db6d233c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ssxAU4Cvac9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
